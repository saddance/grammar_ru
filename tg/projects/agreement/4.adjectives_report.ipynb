{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалось получить confusion-матрицу из единиц на диагонали для прилагательных одного склонения. (НОВЫЙ и ХОРОШИЙ)\n",
    "\n",
    "Теперь хотим собрать одну сеть для предсказания окончания всех склонений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T12:36:16.436896968Z",
     "start_time": "2023-10-22T12:36:15.635609182Z"
    }
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import seaborn as sns\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "from tg.grammar_ru.common import Loc\n",
    "from tg.grammar_ru.corpus import CorpusReader, CorpusBuilder, BucketCorpusBalancer\n",
    "from tg.grammar_ru.corpus.corpus_reader import read_data\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(Loc.root_path / 'environment.env')\n",
    "from tg.grammar_ru.components.yandex_storage.s3_yandex_helpers import S3YandexHandler\n",
    "from tg.grammar_ru.components.yandex_delivery.training_logs import S3TrainingLogsLoader, TrainingLogsViewer\n",
    "\n",
    "from yo_fluq_ds import Queryable, Query, fluq\n",
    "import plotly.express as px\n",
    "from tg.grammar_ru.common import Separator\n",
    "\n",
    "from typing import List, Union\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tg.common import DataBundle\n",
    "from tg.common.ml.batched_training import IndexedDataBundle\n",
    "from tg.grammar_ru.components.plain_context_builder import PlainContextBuilder\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "from analysis_tools import get_training_results, plot_metrics, plot_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T12:36:16.440821252Z",
     "start_time": "2023-10-22T12:36:16.438879598Z"
    }
   },
   "outputs": [],
   "source": [
    "from tg.common import DataBundle\n",
    "from tg.common.ml.batched_training import IndexedDataBundle\n",
    "from tg.grammar_ru.components.plain_context_builder import PlainContextBuilder\n",
    "bundle_0_declination_path = Loc.data_cache_path/'bundles/agreement/mid50_0_declination'\n",
    "bundle_all_declination_path = Loc.data_cache_path/'bundles/agreement/mid50_all_decl'\n",
    "project_name = 'agreementproject'\n",
    "# dataset_name = 'agreement_adj_mid50_all_decl_masked'\n",
    "bucket = 'agreementadjbucket'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "endings & calculate masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T12:36:16.446858913Z",
     "start_time": "2023-10-22T12:36:16.442866597Z"
    }
   },
   "outputs": [],
   "source": [
    "NEW = {'ая', 'ого', 'ое', 'ой', 'ом', 'ому',\n",
    "       'ую', 'ые', 'ый', 'ым', 'ыми', 'ых'}\n",
    "# NOTE выкинули 'ою'\n",
    "\n",
    "GOOD = {'ая', 'его', 'ее', 'ей', 'ем', 'ему',\n",
    "        'ие', 'ий', 'им', 'ими', 'их', 'ую', 'яя', 'юю',\n",
    "        'ого','ое', 'ой', 'ому', 'ом'} # легкий\n",
    "\n",
    "BIG = {'ая', 'ие', 'им', 'ими', 'их', 'ого',\n",
    "       'ое', 'ой', 'ом', 'ому', 'ую',\n",
    "       'ые', 'ым', 'ыми', 'ых'} # золотой\n",
    "# NOTE выкинули 'ою'\n",
    "\n",
    "NEW_list = sorted(list(NEW))\n",
    "GOOD_list = sorted(list(GOOD))\n",
    "BIG_list = sorted(list(BIG))\n",
    "# окончания с повторами. это фича.\n",
    "ALL_ENDS_list = NEW_list + GOOD_list + BIG_list\n",
    "POSSIBLE_ENDINGS = set(ALL_ENDS_list)\n",
    "endings_nums = {e: i for i, e in enumerate(ALL_ENDS_list)}\n",
    "\n",
    "NEW_num_by_end = {e: i for i, e in enumerate(NEW_list)}\n",
    "GOOD_num_by_end = {e: i+len(NEW_num_by_end) for i, e in enumerate(GOOD_list)}\n",
    "BIG_num_by_end = {e: i+len(NEW_num_by_end)+len(GOOD_num_by_end)\n",
    "                  for i, e in enumerate(BIG_list)}\n",
    "\n",
    "nums_by_decl_and_end = (\n",
    "    {('new', e): n for e, n in NEW_num_by_end.items()} |\n",
    "    {('good', e): n for e, n in GOOD_num_by_end.items()} |\n",
    "    {('big', e): n for e, n in BIG_num_by_end.items()}\n",
    ")\n",
    "end_num_df = pd.DataFrame(list((0, e, n) for e, n in NEW_num_by_end.items()) +\n",
    "                          list((1, e, n) for e, n in GOOD_num_by_end.items()) +\n",
    "                          list((2, e, n) for e, n in BIG_num_by_end.items()),\n",
    "                          columns=['declension_type', 'ending', 'n']\n",
    "                          )\n",
    "mask_NEW = (end_num_df.declension_type==0).astype(int).values\n",
    "mask_GOOD = (end_num_df.declension_type==1).astype(int).values\n",
    "mask_BIG = (end_num_df.declension_type==2).astype(int).values\n",
    "end_by_num = {n: e for (dt, e), n in nums_by_decl_and_end.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T12:36:16.494307738Z",
     "start_time": "2023-10-22T12:36:16.447019553Z"
    }
   },
   "outputs": [],
   "source": [
    "# end_num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T12:36:16.494596962Z",
     "start_time": "2023-10-22T12:36:16.491672366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(12, 19, 15)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NEW), len(GOOD), len(BIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T12:36:16.494667098Z",
     "start_time": "2023-10-22T12:36:16.491772879Z"
    }
   },
   "outputs": [],
   "source": [
    "# nums_by_decl_and_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T12:36:16.494710189Z",
     "start_time": "2023-10-22T12:36:16.491808877Z"
    }
   },
   "outputs": [],
   "source": [
    "# end_by_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T12:36:16.494746861Z",
     "start_time": "2023-10-22T12:36:16.491838218Z"
    }
   },
   "outputs": [],
   "source": [
    "# decl_end_by_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T12:36:16.495032812Z",
     "start_time": "2023-10-22T12:36:16.491865672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                 mask0  mask1  mask2  mask3  mask4  mask5  mask6  mask7  \\\ndeclension_type                                                           \n0                    1      1      1      1      1      1      1      1   \n1                    0      0      0      0      0      0      0      0   \n2                    0      0      0      0      0      0      0      0   \n\n                 mask8  mask9  ...  mask36  mask37  mask38  mask39  mask40  \\\ndeclension_type                ...                                           \n0                    1      1  ...       0       0       0       0       0   \n1                    0      0  ...       0       0       0       0       0   \n2                    0      0  ...       1       1       1       1       1   \n\n                 mask41  mask42  mask43  mask44  mask45  \ndeclension_type                                          \n0                     0       0       0       0       0  \n1                     0       0       0       0       0  \n2                     1       1       1       1       1  \n\n[3 rows x 46 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mask0</th>\n      <th>mask1</th>\n      <th>mask2</th>\n      <th>mask3</th>\n      <th>mask4</th>\n      <th>mask5</th>\n      <th>mask6</th>\n      <th>mask7</th>\n      <th>mask8</th>\n      <th>mask9</th>\n      <th>...</th>\n      <th>mask36</th>\n      <th>mask37</th>\n      <th>mask38</th>\n      <th>mask39</th>\n      <th>mask40</th>\n      <th>mask41</th>\n      <th>mask42</th>\n      <th>mask43</th>\n      <th>mask44</th>\n      <th>mask45</th>\n    </tr>\n    <tr>\n      <th>declension_type</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 46 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = pd.DataFrame(np.stack([mask_NEW,mask_GOOD, mask_BIG]), columns=[\n",
    "    f'mask{i}' for i in range(len(mask_NEW))\n",
    "])\n",
    "masks.index.name = 'declension_type'\n",
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T12:36:16.495098645Z",
     "start_time": "2023-10-22T12:36:16.491946385Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add masks to bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T12:36:16.495139106Z",
     "start_time": "2023-10-22T12:36:16.491975444Z"
    }
   },
   "outputs": [],
   "source": [
    "from tg.projects.agreement.bundles_tools import set_mask, upload_bundle\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T12:36:16.612242438Z",
     "start_time": "2023-10-22T12:36:16.492003032Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "/home/matvey/PycharmProjects/grammar_ru/data-cache/bundles/agreement/tiny_all_decl is neither file nor folder",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m tiny_all_decl_path \u001B[38;5;241m=\u001B[39m Loc\u001B[38;5;241m.\u001B[39mdata_cache_path\u001B[38;5;241m/\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbundles/agreement/tiny_all_decl\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      2\u001B[0m tiny_all_decl_masked_path \u001B[38;5;241m=\u001B[39m Loc\u001B[38;5;241m.\u001B[39mdata_cache_path \u001B[38;5;241m/\u001B[39m \\\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbundles/agreement/tiny_all_decl_masked\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 4\u001B[0m db_tiny \u001B[38;5;241m=\u001B[39m \u001B[43mDataBundle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtiny_all_decl_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m set_mask(tiny_all_decl_path, tiny_all_decl_masked_path, masks)\n\u001B[1;32m      6\u001B[0m upload_bundle(tiny_all_decl_masked_path,\n\u001B[1;32m      7\u001B[0m               \u001B[38;5;124m'\u001B[39m\u001B[38;5;124magreement_adj_tiny_all_decl_masked\u001B[39m\u001B[38;5;124m'\u001B[39m, bucket, project_name)\n",
      "File \u001B[0;32m~/PycharmProjects/grammar_ru/tg/common/_common/data_bundle.py:120\u001B[0m, in \u001B[0;36mDataBundle.load\u001B[0;34m(inp)\u001B[0m\n\u001B[1;32m    118\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataBundle\u001B[38;5;241m.\u001B[39m_read_bundle(inp)\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 120\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00minp\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is neither file nor folder\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: /home/matvey/PycharmProjects/grammar_ru/data-cache/bundles/agreement/tiny_all_decl is neither file nor folder"
     ]
    }
   ],
   "source": [
    "tiny_all_decl_path = Loc.data_cache_path/f'bundles/agreement/tiny_all_decl'\n",
    "tiny_all_decl_masked_path = Loc.data_cache_path / \\\n",
    "    f'bundles/agreement/tiny_all_decl_masked'\n",
    "db_tiny = DataBundle.load(tiny_all_decl_path)\n",
    "set_mask(tiny_all_decl_path, tiny_all_decl_masked_path, masks)\n",
    "upload_bundle(tiny_all_decl_masked_path,\n",
    "              'agreement_adj_tiny_all_decl_masked', bucket, project_name)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.563269292Z"
    }
   },
   "outputs": [],
   "source": [
    "mid_all_decl_path = Loc.data_cache_path/f'bundles/agreement/mid50_all_decl'\n",
    "mid_all_decl_masked_path = Loc.data_cache_path / \\\n",
    "    f'bundles/agreement/mid50_all_decl_masked'\n",
    "# db = DataBundle.load(mid_all_decl_path)\n",
    "# set_mask(mid_all_decl_path, mid_all_decl_masked_path, masks)\n",
    "# upload_bundle(mid_all_decl_masked_path,\n",
    "#               'agreement_adj_mid50_all_decl_masked', bucket, project_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.573692817Z"
    }
   },
   "outputs": [],
   "source": [
    "td = db.index[db.index.split.isin(['train','display'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.573788692Z"
    }
   },
   "outputs": [],
   "source": [
    "# td.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.573819740Z"
    }
   },
   "outputs": [],
   "source": [
    "import eule\n",
    "diagram = eule.euler({\n",
    "    'new':list(NEW),\n",
    "    'good':list(GOOD),\n",
    "    'big':list(BIG),\n",
    "                      })\n",
    "print(diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.573847843Z"
    }
   },
   "outputs": [],
   "source": [
    "from tg.grammar_ru.features import PyMorphyFeaturizer, SlovnetFeaturizer, SyntaxTreeFeaturizer, SyntaxStatsFeaturizer\n",
    "from tg.grammar_ru.common import Loc\n",
    "from yo_fluq_ds import *\n",
    "\n",
    "from tg.grammar_ru.corpus import CorpusBuilder\n",
    "from tg.projects.agreement.bundle import AdjAgreementTrainIndexBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.573873974Z"
    }
   },
   "outputs": [],
   "source": [
    "BALANCED_PATH = Loc.corpus_path/\"prepare/balanced/books&pub_tiny_balanced.zip\"\n",
    "reader = CorpusReader(BALANCED_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.573904817Z"
    }
   },
   "outputs": [],
   "source": [
    "# df =AdjAgreementTrainIndexBuilder().select(_,reader.get_frames().first(),_)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.573980450Z"
    }
   },
   "outputs": [],
   "source": [
    "# job_name = 'datasphere/agreementproject/job_info/job_agreementproject_16:10:07.829611.txt'\n",
    "# metrics, result_df, y_true, y_pred, tasks = get_training_results(bucket,job_name, project_name)\n",
    "\n",
    "\n",
    "# plot_metrics(metrics, tasks[0])\n",
    "# sorted_nums = sorted(list(y_true.unique()))\n",
    "# cm = pd.DataFrame(\n",
    "#     confusion_matrix(y_true, y_pred,\n",
    "#                         # normalize='true'\n",
    "#                      ).round(2),\n",
    "#     columns=[f'pred {decl_end_by_num[n]}' for n in sorted_nums],\n",
    "#     index=[f'actual {decl_end_by_num[n]}' for n in sorted_nums]\n",
    "# )\n",
    "# plot_cm(cm)\n",
    "# cm = pd.DataFrame(\n",
    "#     confusion_matrix(y_true, y_pred,\n",
    "#                         normalize='true'\n",
    "#                      ).round(2),\n",
    "#     columns=[f'pred {ending_by_num[n]}({n})' for n in sorted_nums],\n",
    "#     index=[f'actual {ending_by_num[n]}({n})' for n in sorted_nums]\n",
    "# )\n",
    "# plot_cm(cm)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.574010109Z"
    }
   },
   "outputs": [],
   "source": [
    "# job_name = 'datasphere/agreementproject/job_info/job_agreementproject_11:17:37.547687.txt'\n",
    "job_name = 'datasphere/agreementproject/job_info/job_agreementproject_11:22:48.589289.txt'\n",
    "metrics, result_df, y_true, y_pred, tasks = get_training_results(bucket,job_name, project_name)\n",
    "\n",
    "\n",
    "plot_metrics(metrics, tasks[0])\n",
    "sorted_nums = sorted(list(y_true.unique()))\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred,\n",
    "                        # normalize='true'\n",
    "                     ).round(2),\n",
    "    columns=[f'pred {n} {end_by_num[n]}' for n in sorted_nums],\n",
    "    index=[f'actual {n} {end_by_num[n]}' for n in sorted_nums]\n",
    ")\n",
    "plot_cm(cm)\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred,\n",
    "                        normalize='true'\n",
    "                     ).round(2),\n",
    "    columns=[f'pred {n} {end_by_num[n]}' for n in sorted_nums],\n",
    "    index=[f'actual {n} {end_by_num[n]}' for n in sorted_nums]\n",
    ")\n",
    "plot_cm(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.574036128Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_columns = [f\"predicted_label_{i}\" for i in range(45)]\n",
    "result_df[pred_columns].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.574062922Z"
    }
   },
   "outputs": [],
   "source": [
    "end_num_df.groupby('declension_type').n.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.574089725Z"
    }
   },
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.574115661Z"
    }
   },
   "outputs": [],
   "source": [
    "db = DataBundle.load(mid_all_decl_masked_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.574172019Z"
    }
   },
   "outputs": [],
   "source": [
    "db.index.declension_type.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.574836378Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(db.index.label, histnorm=None)\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## startified. mask is ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.575707891Z"
    }
   },
   "outputs": [],
   "source": [
    "job_name = 'datasphere/agreementproject/job_info/job_agreementproject_07:29:36.404686.txt'\n",
    "metrics, result_df, y_true, y_pred, tasks = get_training_results(bucket,job_name, project_name)\n",
    "\n",
    "\n",
    "plot_metrics(metrics, tasks[0])\n",
    "sorted_nums = sorted(list(y_true.unique()))\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred,\n",
    "                        # normalize='true'\n",
    "                     ).round(2),\n",
    "    columns=[f'pred {n} {end_by_num[n]}' for n in sorted_nums],\n",
    "    index=[f'actual {n} {end_by_num[n]}' for n in sorted_nums]\n",
    ")\n",
    "plot_cm(cm)\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred,\n",
    "                        normalize='true'\n",
    "                     ).round(2),\n",
    "    columns=[f'pred {n} {end_by_num[n]}' for n in sorted_nums],\n",
    "    index=[f'actual {n} {end_by_num[n]}' for n in sorted_nums]\n",
    ")\n",
    "plot_cm(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.576590631Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_columns = [f\"predicted_label_{i}\" for i in range(45)]\n",
    "result_df[pred_columns].rename(columns={f\"predicted_label_{i}\":f'pr_{i}' for i in range(45)}).sum()#.sum(axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## startified with masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.577321497Z"
    }
   },
   "outputs": [],
   "source": [
    "job_name = 'datasphere/agreementproject/job_info/job_agreementproject_09:28:28.541363.txt'\n",
    "metrics, result_df, y_true, y_pred, tasks = get_training_results(bucket,job_name, project_name)\n",
    "\n",
    "\n",
    "plot_metrics(metrics, tasks[0])\n",
    "sorted_nums = sorted(list(y_true.unique()))\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred,\n",
    "                        # normalize='true'\n",
    "                     ).round(2),\n",
    "    columns=[f'pred {n} {end_by_num[n]}' for n in sorted_nums],\n",
    "    index=[f'actual {n} {end_by_num[n]}' for n in sorted_nums]\n",
    ")\n",
    "plot_cm(cm)\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred,\n",
    "                        normalize='true'\n",
    "                     ).round(2),\n",
    "    columns=[f'pred {n} {end_by_num[n]}' for n in sorted_nums],\n",
    "    index=[f'actual {n} {end_by_num[n]}' for n in sorted_nums]\n",
    ")\n",
    "plot_cm(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.619618231Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_columns = [f\"predicted_label_{i}\" for i in range(45)]\n",
    "d = result_df[pred_columns].rename(columns={f\"predicted_label_{i}\":f'pr_{i}' for i in range(45)}).round(2)\n",
    "d[[f\"pr_{i}\" for i in range(12\n",
    "                            )]].sum()#.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.619683523Z"
    }
   },
   "outputs": [],
   "source": [
    "d.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.619704876Z"
    }
   },
   "outputs": [],
   "source": [
    "d[[f\"pr_{i}\" for i in range(12)]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Не учится\n",
    "\n",
    "Возьмем из бандла 2 типа склонения и 2 окончания. Должно обучиться.\n",
    "Маски проставлены. Они такие же как в mid masked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.619732930Z"
    }
   },
   "outputs": [],
   "source": [
    "db = DataBundle.load(mid_all_decl_masked_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.619758727Z"
    }
   },
   "outputs": [],
   "source": [
    "four_labels = {0,5, 18, 19}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.619777660Z"
    }
   },
   "outputs": [],
   "source": [
    "four_labels_path = mid_all_decl_masked_path.parent / 'debug4labels'\n",
    "db['index'] = db.index[db.index.label.isin(four_labels)]\n",
    "db = db.copy()\n",
    "db.save(four_labels_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.619795318Z"
    }
   },
   "outputs": [],
   "source": [
    "job_name = 'datasphere/agreementproject/job_info/job_agreementproject_16:49:45.454601.txt'\n",
    "metrics, result_df, y_true, y_pred, tasks = get_training_results(bucket,job_name, project_name)\n",
    "\n",
    "\n",
    "plot_metrics(metrics, tasks[0])\n",
    "sorted_nums = sorted(list(y_true.unique()))\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred,\n",
    "                        # normalize='true'\n",
    "                     ).round(2),\n",
    "    columns=[f'pred {n} {end_by_num[n]}' for n in sorted_nums],\n",
    "    index=[f'actual {n} {end_by_num[n]}' for n in sorted_nums]\n",
    ")\n",
    "plot_cm(cm)\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred,\n",
    "                        normalize='true'\n",
    "                     ).round(2),\n",
    "    columns=[f'pred {n} {end_by_num[n]}' for n in sorted_nums],\n",
    "    index=[f'actual {n} {end_by_num[n]}' for n in sorted_nums]\n",
    ")\n",
    "plot_cm(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.619814024Z"
    }
   },
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.619832419Z"
    }
   },
   "outputs": [],
   "source": [
    "from tg.projects.agreement.bundle import NounAgreementTrainIndexBuilder\n",
    "end_by_num = NounAgreementTrainIndexBuilder.end_by_num\n",
    "# end_by_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.619851283Z"
    }
   },
   "outputs": [],
   "source": [
    "job_name = 'datasphere/agreementproject/job_info/job_agreementproject_17:37:48.202196.txt'\n",
    "metrics, result_df, y_true, y_pred, tasks = get_training_results(bucket,job_name, project_name)\n",
    "\n",
    "\n",
    "plot_metrics(metrics, tasks[0])\n",
    "sorted_nums = sorted(list(y_true.unique()))\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred,\n",
    "                        # normalize='true'\n",
    "                     ).round(2),\n",
    "    columns=[f'pred {n} {end_by_num[n]}' for n in sorted_nums],\n",
    "    index=[f'actual {n} {end_by_num[n]}' for n in sorted_nums]\n",
    ")\n",
    "plot_cm(cm)\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred,\n",
    "                        normalize='true'\n",
    "                     ).round(2),\n",
    "    columns=[f'pred {n} {end_by_num[n]}' for n in sorted_nums],\n",
    "    index=[f'actual {n} {end_by_num[n]}' for n in sorted_nums]\n",
    ")\n",
    "plot_cm(cm)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40 ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.619869963Z"
    }
   },
   "outputs": [],
   "source": [
    "job_name = 'datasphere/agreementproject/job_info/job_agreementproject_05:58:45.668861.txt'\n",
    "metrics, result_df, y_true, y_pred, tasks = get_training_results(bucket,job_name, project_name)\n",
    "\n",
    "\n",
    "plot_metrics(metrics, tasks[0])\n",
    "sorted_nums = sorted(list(y_true.unique()))\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred,\n",
    "                        # normalize='true'\n",
    "                     ).round(2),\n",
    "    columns=[f'pred {n} {end_by_num[n]}' for n in sorted_nums],\n",
    "    index=[f'actual {n} {end_by_num[n]}' for n in sorted_nums]\n",
    ")\n",
    "plot_cm(cm)\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred,\n",
    "                        normalize='true'\n",
    "                     ).round(2),\n",
    "    columns=[f'pred {n} {end_by_num[n]}' for n in sorted_nums],\n",
    "    index=[f'actual {n} {end_by_num[n]}' for n in sorted_nums]\n",
    ")\n",
    "plot_cm(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.619921991Z"
    }
   },
   "outputs": [],
   "source": [
    "db = DataBundle.load(Loc.data_cache_path / \\\n",
    "    f'bundles/agreement/noun_mid50')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.619949742Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(db.index.label.map(end_by_num), histnorm=None)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.619968791Z"
    }
   },
   "outputs": [],
   "source": [
    "end_by_num"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with norm end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T12:36:16.736806371Z",
     "start_time": "2023-10-22T12:36:16.619987827Z"
    }
   },
   "outputs": [],
   "source": [
    "job_name = 'datasphere/agreementproject/job_info/job_agreementproject_10:45:55.499540.txt'\n",
    "metrics, result_df, y_true, y_pred, tasks = get_training_results(bucket,job_name, project_name)\n",
    "\n",
    "\n",
    "plot_metrics(metrics, tasks[0])\n",
    "sorted_nums = sorted(list(y_true.unique()))\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred,\n",
    "                        # normalize='true'\n",
    "                     ).round(2),\n",
    "    columns=[f'pred {n} {end_by_num[n]}' for n in sorted_nums],\n",
    "    index=[f'actual {n} {end_by_num[n]}' for n in sorted_nums]\n",
    ")\n",
    "plot_cm(cm)\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred,\n",
    "                        normalize='true'\n",
    "                     ).round(2),\n",
    "    columns=[f'pred {n} {end_by_num[n]}' for n in sorted_nums],\n",
    "    index=[f'actual {n} {end_by_num[n]}' for n in sorted_nums]\n",
    ")\n",
    "plot_cm(cm)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -a without adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.620012619Z"
    }
   },
   "outputs": [],
   "source": [
    "from tg.projects.agreement.bundle import NounAgreementTrainIndexBuilder\n",
    "end_by_num = NounAgreementTrainIndexBuilder.end_by_num\n",
    "end_by_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.620031367Z"
    }
   },
   "outputs": [],
   "source": [
    "job_name = 'datasphere/agreementproject/job_info/job_agreementproject_11:17:53.260554.txt'\n",
    "metrics, result_df, y_true, y_pred, tasks = get_training_results(bucket,job_name, project_name)\n",
    "\n",
    "\n",
    "plot_metrics(metrics, tasks[0])\n",
    "sorted_nums = sorted(list(y_true.unique()))\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred,\n",
    "                        # normalize='true'\n",
    "                     ).round(2),\n",
    "    columns=[f'pred {n} {end_by_num[n]}' for n in sorted_nums],\n",
    "    index=[f'actual {n} {end_by_num[n]}' for n in sorted_nums]\n",
    ")\n",
    "plot_cm(cm)\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred,\n",
    "                        normalize='true'\n",
    "                     ).round(2),\n",
    "    columns=[f'pred {n} {end_by_num[n]}' for n in sorted_nums],\n",
    "    index=[f'actual {n} {end_by_num[n]}' for n in sorted_nums]\n",
    ")\n",
    "plot_cm(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T12:36:16.620049748Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

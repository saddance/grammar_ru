{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from tg.grammar_ru.features import PyMorphyFeaturizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8789136f565357e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tg.grammar_ru import Loc\n",
    "\n",
    "CORPUS_NAMES = [\n",
    "    \"books.base.zip\",\n",
    "    \"pub.base.zip\",\n",
    "    \"lenta.base.zip\"\n",
    "]\n",
    "#TODO: add smth else?\n",
    "\n",
    "CORPUS_LIST = [Loc.corpus_path / corpus_name for corpus_name in CORPUS_NAMES]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "891684db2f6aa208"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from yo_fluq_ds import *\n",
    "from tg.grammar_ru import Separator\n",
    "from tg.grammar_ru.corpus.corpus_reader import CorpusReader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57f46adf755bc7c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "viewer = Separator.Viewer()\n",
    "\n",
    "texts = list(CorpusReader.read_frames_from_several_corpora(CORPUS_LIST)\n",
    "             .feed(fluq.with_progress_bar(console=None))\n",
    "             .select(viewer.to_text)\n",
    "             )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d96cec3b88ae8da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "\n",
    "with jsonlines.open('texts.jsonl', 'w') as write:\n",
    "    write.write_all(texts)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "782342bcd1f52858"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "\n",
    "with jsonlines.open('texts.jsonl') as read:\n",
    "    texts2 = [t for t in read]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b1e61a7a033327b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "sents = list(itertools.chain.from_iterable(text.splitlines() for text in texts2))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "403e5f7477a3813"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(sents)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c023641f6ea6b8fb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(sents)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a19292c332f58a18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tg.common import DataBundle\n",
    "\n",
    "db = DataBundle.load('mytest_db.zip')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fee0db89d3e98e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tg.grammar_ru.features import PyMorphyFeaturizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f10d1024f5338f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tg.grammar_ru.features import PyMorphyFeaturizer\n",
    "\n",
    "db = Separator.build_bundle(sents[:100000], [PyMorphyFeaturizer()])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3af864f3c45152ab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "db.src = db.src.join(db.pymorphy, on='word_id')\n",
    "db.src.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcb0203ce74241f8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "db.pymorphy[db.pymorphy.POS == 'ADJS'].info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b3e4e16c75452a1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "db.pymorphy[db.pymorphy.POS == 'ADJF'].info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4374db1a967fa24c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "db.adjectives.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "576ae0818449a10e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "WINDOW_SIZE = 7"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3956f0f8b83ec0a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "features = ['POS', 'gender', 'number', 'case', 'animacy', 'aspect', 'transitivity', 'person', 'tense', 'mood', 'voice', 'involvement']\n",
    "\n",
    "def get_offset_word_feats(word_row, offset) -> dict:\n",
    "    result = {}\n",
    "    for feat in features:\n",
    "        result[f'{feat}_{offset}'] = word_row[feat]\n",
    "    result[f'OFFSET_{offset}'] = f'OFFSET_{offset}'\n",
    "    return result\n",
    "\n",
    "def get_empty_feats(offset) -> dict:\n",
    "    result = {}\n",
    "    for feat in features:\n",
    "        result[f'{feat}_{offset}'] = np.nan\n",
    "    result[f'OFFSET_{offset}'] = f'OFFSET_{offset}'\n",
    "    return result\n",
    "\n",
    "\n",
    "adj_dataset = []\n",
    "\n",
    "for sent_id, sentence_df in tqdm(db.src.groupby('sentence_id')):\n",
    "    for idx in sentence_df.index[sentence_df.POS.eq('ADJS') | sentence_df.POS.eq('ADJF')]:\n",
    "        adj_window_data = {}\n",
    "        for offset in range(-WINDOW_SIZE, WINDOW_SIZE + 1):\n",
    "            if idx + offset not in sentence_df.index:\n",
    "                adj_window_data.update(get_empty_feats(offset))\n",
    "            else:\n",
    "                adj_window_data.update(get_offset_word_feats(sentence_df.loc[idx + offset], offset))\n",
    "        \n",
    "        adj_dataset.append(adj_window_data)\n",
    "                "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19fcadc6e5f34204"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "adj_df = pd.DataFrame.from_records(adj_dataset)\n",
    "adj_df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22799f19b2840d18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "adj_df = adj_df.fillna('missing')\n",
    "adj_df.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1dc1a04783e25db"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "adj_df = adj_df.astype('category')\n",
    "adj_df.info(memory_usage='deep')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6426df32853d7481"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "db.data_frames['adjectives'] = adj_df\n",
    "db.adjectives"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "426f26f37ae48f9f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "db.save_as_zip('mytest_db.zip')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35ff1e84ed4a4d3f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "adj_center_predict_features = ['gender_0', 'number_0', 'case_0', 'animacy_0']\n",
    "adj_center_expect_features = ['POS_0']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8265156bfed55de"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(db.adjectives, test_size=0.2, random_state=228)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce48972d4ea43de0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(train_df), len(test_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f10083cf518a4ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_features = [col for col in db.adjectives.columns if col[-1] != '0' or col in adj_center_expect_features]\n",
    "label_features = [col for col in db.adjectives.columns if col in adj_center_predict_features]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6547917d8bb294e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for label_feat in label_features:\n",
    "    print(label_feat, db.adjectives[label_feat].value_counts())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19dcb7276f73f07b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist')\n",
    "ohe.fit(train_df[label_features])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d43b269c651c60ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_ = ohe.transform(db.adjectives[label_features])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39797b989a1b7f61"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label_features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd7dd352dc56e699"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NEW = {'ая', 'ого', 'ое', 'ой', 'ом', 'ому',\n",
    "       'ую', 'ые', 'ый', 'ым', 'ыми', 'ых'}\n",
    "# NOTE выкинули 'ою'\n",
    "\n",
    "GOOD = {'ая', 'его', 'ее', 'ей', 'ем', 'ему',\n",
    "        'ие', 'ий', 'им', 'ими', 'их', 'ую', 'яя', 'юю',\n",
    "        'ого','ое', 'ой', 'ому', 'ом'} # легкий\n",
    "\n",
    "BIG = {'ая', 'ие', 'им', 'ими', 'их', 'ого',\n",
    "       'ое', 'ой', 'ом', 'ому', 'ую',\n",
    "       'ые', 'ым', 'ыми', 'ых'} # золотой\n",
    "# NOTE выкинули 'ою'\n",
    "\n",
    "NEW_list = sorted(list(NEW))\n",
    "GOOD_list = sorted(list(GOOD))\n",
    "BIG_list = sorted(list(BIG))\n",
    "# окончания с повторами. это фича.\n",
    "ALL_ENDS_list = NEW_list + GOOD_list + BIG_list\n",
    "POSSIBLE_ENDINGS = set(ALL_ENDS_list)\n",
    "endings_nums = {e: i for i, e in enumerate(ALL_ENDS_list)}\n",
    "\n",
    "NEW_num_by_end = {e: i for i, e in enumerate(NEW_list)}\n",
    "GOOD_num_by_end = {e: i+len(NEW_num_by_end) for i, e in enumerate(GOOD_list)}\n",
    "BIG_num_by_end = {e: i+len(NEW_num_by_end)+len(GOOD_num_by_end)\n",
    "                  for i, e in enumerate(BIG_list)}\n",
    "\n",
    "nums_by_decl_and_end = (\n",
    "        {('new', e): n for e, n in NEW_num_by_end.items()} |\n",
    "        {('good', e): n for e, n in GOOD_num_by_end.items()} |\n",
    "        {('big', e): n for e, n in BIG_num_by_end.items()}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "822269a860c5c4cd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import catboost\n",
    "\n",
    "model = catboost.CatBoostClassifier(\n",
    "    objective='MultiLogloss',\n",
    "    iterations=1000,\n",
    "    custom_metric='F1',\n",
    "    task_type='GPU'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a06b4cd3dce7703"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data = catboost.Pool(data=train_df[input_features], label=ohe.transform(train_df[label_features]), cat_features=input_features)\n",
    "test_data = catboost.Pool(data=test_df[input_features], label=ohe.transform(test_df[label_features]), cat_features=input_features)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10a4250af9e8b9f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_data,\n",
    "    eval_set=test_data,\n",
    "    verbose=50,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59e239923c38ae23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.get_feature_importance(prettified=True)[:50]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c51f650c2128812"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.best_score_"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bef11463467c2b15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import joblib\n",
    "\n",
    "MODEL_PATH = pathlib.Path('catboost_adjectives.joblib')\n",
    "OHE_ADJECTIVES_PATH = pathlib.Path('ohe_adjectives.joblib')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fd6e25001191a5e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save_model(MODEL_PATH)\n",
    "joblib.dump(ohe, OHE_ADJECTIVES_PATH)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abe40e7d1fbc0026"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import joblib\n",
    "import pymorphy2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import catboost\n",
    "\n",
    "features = ['POS', 'gender', 'number', 'case', 'animacy', 'aspect', 'transitivity', 'person', 'tense', 'mood', 'voice', 'involvement']\n",
    "\n",
    "def get_offset_word_feats(word_row, offset: int) -> dict:\n",
    "    result = {}\n",
    "    for feat in features:\n",
    "        result[f'{feat}_{offset}'] = word_row[feat]\n",
    "    result[f'OFFSET_{offset}'] = f'OFFSET_{offset}'\n",
    "    return result\n",
    "\n",
    "def get_empty_feats(offset: int) -> dict:\n",
    "    result = {}\n",
    "    for feat in features:\n",
    "        result[f'{feat}_{offset}'] = np.nan\n",
    "    result[f'OFFSET_{offset}'] = f'OFFSET_{offset}'\n",
    "    return result\n",
    "\n",
    "\n",
    "def inflect_with_labels(morph, word: str, labels: list) -> str:\n",
    "    parsed = morph.parse(word)[0]\n",
    "    return parsed.inflect(set(labels) - {'missing', None}).word\n",
    "    \n",
    "\n",
    "class AdjectivesSuggestionsGenerator:\n",
    "    def __init__(self, model_path: pathlib.Path, one_hot_encoding_path: pathlib.Path, window_size: int = 7):\n",
    "        self._morph = pymorphy2.MorphAnalyzer(lang='ru')\n",
    "        self._model = catboost.CatBoostClassifier().load_model(str(model_path))\n",
    "        self._one_hot_encoding = joblib.load(one_hot_encoding_path)\n",
    "        self._window_size = window_size\n",
    "\n",
    "    def get_adjectives_suggestions(self, text: str) -> pd.DataFrame | None:\n",
    "        text_db = Separator.build_bundle(text, [PyMorphyFeaturizer()])\n",
    "        text_df = text_db.src.join(text_db.pymorphy, on='word_id')\n",
    "        \n",
    "        adj_window_datas = []\n",
    "        indices = []\n",
    "        \n",
    "        for idx in text_df.index[text_df.POS.eq('ADJS') | text_df.POS.eq('ADJF')]:\n",
    "            adj_window_data = {}\n",
    "            for offset in range(-self._window_size, self._window_size + 1):\n",
    "                if idx + offset not in text_df.index:\n",
    "                    adj_window_data.update(get_empty_feats(offset))\n",
    "                else:\n",
    "                    adj_window_data.update(get_offset_word_feats(text_df.loc[idx + offset], offset))\n",
    "\n",
    "            indices.append(idx)\n",
    "            adj_window_datas.append(adj_window_data)\n",
    "        \n",
    "        if not adj_window_datas:\n",
    "            return None\n",
    "        \n",
    "        inp = pd.DataFrame(adj_window_datas)[input_features]\n",
    "        inp = inp.fillna('missing')\n",
    "        pool_inp = catboost.Pool(inp, cat_features=input_features)\n",
    "        predictions_raw = self._model.predict(pool_inp)\n",
    "        \n",
    "        words = text_df.word.loc[indices]\n",
    "        predicted_labels = self._one_hot_encoding.inverse_transform(predictions_raw)\n",
    "        inflected_words = [inflect_with_labels(self._morph, word, labels) for word, labels in zip(words, predicted_labels)]\n",
    "        text_db.src.loc[indices, 'suggestion'] = inflected_words\n",
    "        return text_db.src"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa9c0a1e43630890"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "asg = AdjectivesSuggestionsGenerator(MODEL_PATH, OHE_ADJECTIVES_PATH, window_size=WINDOW_SIZE)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1236a7836d14ccb1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def apply_suggestion(word: str, suggestion: str):\n",
    "    if pd.isna(suggestion):\n",
    "        return word\n",
    "    if word.istitle():\n",
    "        return suggestion.title()\n",
    "    return suggestion"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ea67a8b776c2451"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# test_text = 'Синий машина ехала по скоростная трассе и врезалась в старенькая столбы на ужасная улице' * 100\n",
    "test_text = 'цвета морской волны и цвет морской паруса'\n",
    "\n",
    "df_with_suggestions = asg.get_adjectives_suggestions(test_text)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "add184b31eb8172c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_with_suggestions['word'] = df_with_suggestions[['word', 'suggestion']].apply(lambda x: apply_suggestion(*x), axis=1)\n",
    "Separator.Viewer().to_text(df_with_suggestions)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7284c72467a7734c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2ee9a6aa11cfcad8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
